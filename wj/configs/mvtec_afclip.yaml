inherit_from: configs/base.yaml

experiment:
  name: mvtec_afclip
  description: "AF-CLIP baseline on MVTec-AD"
  output_root: results/mvtec/afclip

data:
  dataset: mvtec_afclip
  root: data
  categories:
    [
      "bottle",
      "cable",
      "capsule",
      "carpet",
      "grid",
      "hazelnut",
      "leather",
      "metal_nut",
      "pill",
      "screw",
      "tile",
      "toothbrush",
      "transistor",
      "wood",
      "zipper",
    ]
  batch_size: 8
  num_workers: 4
  pin_memory: true
  image_size: 518
  loader:
    fewshot: 0
    seed: 122

model:
  name: afclip
  device: cuda
  clip_model: "ViT-L/14@336px"
  clip_download_dir: git_clone/AF-CLIP/download/clip
  prompt_len: 12
  feature_layers: [6, 12, 18, 24]
  memory_layers: [6, 12, 18, 24]
  alpha: 0.1
  fewshot: 0
  interpolate_to_input: true
  gaussian_blur:
    enabled: false
    kernel_size: 5
    sigma: 4.0
  weight:
    dir: git_clone/AF-CLIP/weight
    dataset: mvtec
    strict: false

evaluation:
  metrics:
    compute_image_auroc: true
    compute_pixel_auroc: true
    compute_pro: true
    thresholds:
      image: 100
      pixel: 200
    pro:
      max_fpr: 0.3
      num_thresholds: 200
  latency:
    warmup_iters: 1000
    measure_iters: 1000
    throughput_num_passes: 1000
    gpu_memory_num_iters: 1000

visualization:
  num_examples: 8
  cmap: jet
  save_overlay: true
  overlay_alpha: 0.5

