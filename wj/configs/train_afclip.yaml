inherit_from: configs/base.yaml

experiment:
  name: train_afclip
  description: "AF-CLIP 학습 설정"
  output_root: results/train_afclip
  seed: 122

data:
  dataset: mvtec_afclip
  root: data
  categories:
    - "bottle"
    # 모든 카테고리를 학습하려면 아래 주석을 해제하세요
    # [
    #   "bottle",
    #   "cable",
    #   "capsule",
    #   "carpet",
    #   "grid",
    #   "hazelnut",
    #   "leather",
    #   "metal_nut",
    #   "pill",
    #   "screw",
    #   "tile",
    #   "toothbrush",
    #   "transistor",
    #   "wood",
    #   "zipper",
    # ]
  batch_size: 8
  num_workers: 4
  pin_memory: true
  image_size: 518
  loader:
    fewshot: 0
    seed: 122

model:
  name: afclip
  device: cuda
  clip_model: "ViT-L/14@336px"
  clip_download_dir: git_clone/AF-CLIP/download/clip
  prompt_len: 12
  feature_layers: [6, 12, 18, 24]
  memory_layers: [6, 12, 18, 24]
  alpha: 0.1
  fewshot: 0
  interpolate_to_input: true
  gaussian_blur:
    enabled: false
    kernel_size: 5
    sigma: 4.0
  # 학습 시에는 weight를 로드하지 않음 (새로 학습)
  weight:
    dir: null
    dataset: mvtec
    strict: false

training:
  epochs: 2
  lr: 0.0001
  lambda1: 1.0  # Segmentation loss 가중치
  lambda2: 1.0  # Patch alignment loss 가중치
  save_dir: weights/afclip  # 학습된 가중치 저장 경로
  dataset_name: mvtec  # 저장할 때 사용할 데이터셋 이름 (파일명에 사용)

runtime:
  deterministic: true

